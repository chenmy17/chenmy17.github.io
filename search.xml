<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ç»å…¸å·ç§¯ç¥žç»ç½‘ç»œæ¨¡åž‹ï¼šLeNet-5]]></title>
    <url>%2F2018%2F03%2F26%2F%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%EF%BC%9ALeNet-5%2F</url>
    <content type="text"><![CDATA[ç»å…¸å·ç§¯ç¥žç»ç½‘ç»œæ¨¡åž‹ï¼šLeNet-5æœ€è¿‘åœ¨çœ‹CaiCloudçš„TensorFlowæ¡†æž¶è¿™æœ¬ä¹¦ï¼Œåˆšå¥½çœ‹åˆ°å·ç§¯è¿™ä¸€ç« ï¼Œé¡ºä¾¿åšä¸ªç¬”è®°ï¼Œä»¥å…è¾¹çœ‹è¾¹å¿˜ðŸŒï¼ˆï¿£ã€‚ã€‚ï¿£ï¼‰ å·ç§¯ç¥žç»ç½‘ç»œåœ¨å›¾åƒæ•°æ®é›†ä¸Šæœ‰å¾ˆçªå‡ºçš„è¡¨çŽ°ã€‚ä¸Žå…¨è¿žæŽ¥ç¥žç»ç½‘ç»œä¸åŒçš„æ˜¯ï¼Œå·ç§¯ç¥žç»ç½‘ç»œçš„ç›¸é‚»ä¸¤å±‚çš„èŠ‚ç‚¹å¹¶ä¸æ˜¯éƒ½æœ‰è¿žæŽ¥ã€‚ ðŸ‘†å›¾å°±æ˜¯ä¸€ä¸ªå·ç§¯ç¥žç»ç½‘ç»œçš„åŸºæœ¬æž¶æž„å›¾ã€‚å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œå·ç§¯ç¥žç»ç½‘ç»œå‰å‡ å±‚çš„æ¯ä¸€ä¸ªèŠ‚ç‚¹éƒ½åªä¸Žä¸Šä¸€å±‚çš„éƒ¨åˆ†èŠ‚ç‚¹ç›¸è¿žã€‚ä¸€ä¸ªç¥žç»ç½‘ç»œä¸»è¦ç”±ðŸ‘‡äº”ç§ç»“æž„ç»„æˆï¼š è¾“å…¥å±‚ å·ç§¯å±‚ æ± åŒ–å±‚ å…¨è¿žæŽ¥å±‚ softmaxå±‚ ä»¥LeNet-5çš„TensorFlowå®žçŽ°ä¸ºä¾‹äº†è§£æ¯ä¸€å±‚çš„ä½œç”¨çš„å…·ä½“åŠŸèƒ½ã€‚ ç¥žç»ç½‘ç»œçš„è¾“å…¥å› ä¸ºLeNet-5è§£å†³çš„æ˜¯MNISTæ•°å­—è¯†åˆ«é—®é¢˜ï¼Œæ‰€ä»¥è¾“å…¥æ˜¯åŽŸå§‹å›¾åƒçš„åƒç´ 28Ã—28Ã—1ã€‚å·ç§¯ç¥žç»ç½‘ç»œçš„è¾“å…¥å±‚ä¸ºä¸€ä¸ªä¸‰ç»´çŸ©é˜µï¼Œæ‰€ä»¥è¾“å…¥çš„æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š 12345678x = tf.placeholder(tf.float32,[ #ç¬¬ä¸€ç»´è¡¨ç¤ºä¸€ä¸ªbatchä¸­æ ·ä¾‹çš„ä¸ªæ•° BATCH_SIZE, mnist_inference.IMAGE_SIZE, mnist_inference.IMAGE_SIZE, #å›¾ç‰‡çš„æ·±åº¦ï¼Œå¯¹äºŽRGBå›¾åƒä¸º3 mnist_inference.NUM_CHANNEL], name = &apos;x-input&apos;) ç¥žç»ç½‘ç»œçš„å‚æ•°12345678910111213141516171819import tensorflow as tf#é…ç½®ç¥žç»ç½‘ç»œçš„å‚æ•°INPUT_NODE = 784OUTPUT_NODE = 10IMAGE_SIZE = 28NUM_CHANNELS = 1NUM_LABELS = 10#ç¬¬ä¸€å±‚å·ç§¯çš„å°ºå¯¸å’Œæ·±åº¦CONV1_DEEP = 32CONV1_SIZE = 5#ç¬¬äºŒå±‚å·ç§¯çš„å°ºå¯¸å’Œæ·±åº¦CONV2_DEEP = 64CONV2_SIZE = 5#å…¨è¿žæŽ¥å±‚èŠ‚ç‚¹çš„ä¸ªæ•°FC_SIZE = 512 å·ç§¯ç½‘ç»œå‰å‘ä¼ æ’­è¿‡ç¨‹layer1-conv1 å·ç§¯å±‚12345678def inferecne(input_tensor,train,regularizer): with tf.variabel_scope(&apos;layer1-conv1&apos;): conv1_weights = tf.get_variable( &quot;weight&quot;,[CONV1_SIZE,CONV1_SIZE,NUM_CHANNELS,CONV1_DEEP], initializer=tf.truncated_normal_initializer(stddev=0.1)) conv1_biases = tf.get_variable(&quot;bias&quot;,[CONV1_DEEP],initializer=tf.constant_initializer(0.0) conv1 = tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1],padding=&apos;SAME&apos;) relu1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases)) layer2-pool1 æœ€å¤§æ± åŒ–å±‚12with tf.name_variable(&apos;layer2-pool1&apos;) pool1 = tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&apos;SAME&apos;) layer3-conv2 ç¬¬äºŒå±‚å·ç§¯å±‚1234567with tf.variable_scope(&apos;layer3-conv2&apos;): conv2_weights = tf.get_variable( &quot;weight&quot;,[CONV2_SIZE,CONV2_SIZE,CONV2_DEEP,CONV2_DEEP], initializer=tf.truncated_normal_initializer(stddev=0.1)) conv2_biases = tf.get_variable(&quot;bias&quot;,[CONV1_DEEP],initializer=tf.constant_initializer(0.0) conv2 = tf.nn.conv2d(pool1,conv2_weights,strides=[1,1,1,1],padding=&apos;SAME&apos;) relu2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases)) layer4-pool2 æ± åŒ–å±‚12with tf.name_scope(&apos;layer4-pool1&apos;): pool2 = tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&apos;SAME&apos;) å¯¹æ•°æ®è¿›è¡Œå¤„ç†è¿›å…¥å…¨è¿žæŽ¥å±‚1234pool_shape = pool2.get_shape().as_list()nodes = pool_shape[1]*pool_shape[2]*pool_shape[3]#pool_shape[0]ä¸­ä¸ºä¸€ä¸ªbatchä¸­æ•°æ®çš„ä¸ªæ•°reshaped =tf.reshape(pool2,[pool_shape[0],nodes) layer5-fc1å…¨è¿žæŽ¥å±‚123456789#åœ¨è¿™ä¸€å±‚ä¸­åŠ å…¥äº†dropoutç­–ç•¥é¿å…äº†è¿‡æ‹Ÿåˆçš„é—®é¢˜with tf.variable_scope(&apos;layer5-fc1&apos;): fc1_weights = tf.get_variable(&quot;weight&quot;,[nodes,FC_SIZE],initializer=tf.truncated_normal_initializer(stddev=0.1)) if regularizer!=None: tf.add_to_collection(&apos;losses&apos;,regularizer(fc1_weights)) fc1_biases = tf.get_variable(&quot;bias&quot;,[FC_SIZE],initializer=tf.constant_initializer(0.1)) fc1 = tf.nn.relu(tf.matmul(reshaped,fc1_weights)+fc1_biases) if train: fc1 = tf.nn.dropout(fc1,0.5) layer6-fc2å…¨è¿žæŽ¥å±‚123456789#è¿™ä¸€å±‚çš„è¾“å…¥ä¸º512çš„å‘é‡ï¼Œè¾“å‡ºä¸º10çš„å‘é‡with tf.variable_scope(&apos;layer6-fc2&apos;): fc2_weights = tf.get_variable(&quot;weight&quot;,[FC_SIZE,NUM_LABELS],initializer=tf.truncated_normal_initializer(stddev=0.1)) if regularizer!=None: tf.add_to_collection(&apos;losses&apos;,regularizer(fc2_weights)) fc2_biases = tf.get_variable(&quot;bias&quot;,[NUM_LABELS],initializer=tf.constant_initializer(0.1)) logit = tf.matmul(fc1,fc2_weights)+fc2_biases#è¿”å›žç¬¬å…­å±‚è¾“å‡ºreturn logit]]></content>
      <tags>
        <tag>å­¦ä¹ ç¬”è®°</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflowä¸­å˜é‡å…±äº«çš„é—®é¢˜]]></title>
    <url>%2F2018%2F03%2F24%2FTensorflow%E4%B8%AD%E5%8F%98%E9%87%8F%E5%85%B1%E4%BA%AB%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Tensorflowä¸­å˜é‡å…±äº«çš„é—®é¢˜åœ¨TensorFlowä¸­æä¾›äº†é€šè¿‡å˜é‡åæ¥åˆ›å»ºæˆ–è€…èŽ·å–ä¸€ä¸ªå˜é‡çš„æœºåˆ¶ï¼Œé€šè¿‡è¿™ä¸ªæœºåˆ¶åœ¨ä¸åŒçš„å‡½æ•°ä¸­å¯ä»¥ç›´æŽ¥é€šè¿‡åå­—æ¥ä½¿ç”¨å˜é‡ï¼Œè€Œä¸éœ€è¦å°†å˜é‡ä»¥å½¢å‚çš„å½¢å¼ä¼ é€’ç»™å‡½æ•°ã€‚Tensorflowæä¾›äº†ä¸‰ç§åˆ›å»ºå˜é‡çš„æ–¹å¼ï¼Œtf.placeholder,tf.Variable,tf.get_variableä¸‰ç§æ–¹å¼ã€‚ ä¸‰ç§æ–¹å¼å®šä¹‰å˜é‡è¯•ç€åœ¨TensorFlowä¸­åˆ†åˆ«ç”¨ä¸‰ç§æ–¹å¼å®šä¹‰å˜é‡ï¼Œè§‚å¯Ÿå®ƒä»¬çš„åŒºåˆ«ã€‚ tf.placeholder()æ–¹å¼123456789import tensorflow as tfv1 = tf.placeholder(tf.float32, shape=[1,2,3])print v1.namev1 = tf.placeholder(tf.float32, shape=[1,2,3], name=&apos;ts&apos;)print v1.namev1 = tf.placeholder(tf.float32, shape=[1,2,3], name=&apos;ts&apos;)print v1.nameprint type(v1)print v1 12345Placeholder:0ts:0ts_1:0&lt;class &apos;tensorflow.python.framework.ops.Tensor&apos;&gt;Tensor(&quot;ts_1:0&quot;, shape=(1, 2, 3), dtype=float32) tf.Variable()æ–¹å¼123456789import tensorflow as tfv2 = tf.Variable([1,2], dtype=tf.float32)print v2.namev2 = tf.Variable([1,2], dtype=tf.float32, name=&apos;Y&apos;)print v2.namev2 = tf.Variable([1,2], dtype=tf.float32, name=&apos;Y&apos;)print v2.nameprint type(v2)print v2 12345Variable:0Y:0Y_1:0&lt;class &apos;tensorflow.python.ops.variables.Variable&apos;&gt;&lt;tf.Variable &apos;Y_1:0&apos; shape=(2,) dtype=float32_ref&gt; tf.get_variable()æ–¹å¼1234567# å¯¹äºŽtf.get_variable()æ–¹æ³•æ¥è¯´ï¼Œnameæ˜¯ä¸€ä¸ªå¿…å¡«çš„å‚æ•°v3 = tf.get_variable(name = &apos;fl&apos;, shape=[])print v3.namev4 = tf.get_variable(name = &apos;fl&apos;, shape=[2])print v4.nameprint type(v3)print v3 1234567fl:0#ValueErrorValueError: Variable fl already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:...#æ­¤å¤„æŠ¥äº†ä¸€ä¸ªValueé”™è¯¯&lt;class &apos;tensorflow.python.ops.variables.Variable&apos;&gt;&lt;tf.Variable &apos;fl:0&apos; shape=() dtype=float32_ref&gt; å†æ¥åšä¸€ä¸ªå°å°çš„å®žéªŒ 12345#ç”±ä¸Šè¿°çš„å®žéªŒå¯ä»¥çœ‹å‡ºname=&apos;fl&apos;çš„å˜é‡å’Œv3å†²çªï¼Œæ‰€ä»¥æŠ¥é”™ï¼Œ#æ­¤å¤„v3,v4éƒ½æ˜¯é€šè¿‡tf.get_variable()æ–¹æ³•èµ‹å€¼æ‰€ä»¥äº§ç”Ÿå†²çªã€‚v4 = tf.get_variable(name=&apos;Y&apos;, shape=[1])print type(v4)print v4 12&lt;class &apos;tensorflow.python.ops.variables.Variable&apos;&gt;&lt;tf.Variable &apos;Y_2:0&apos; shape=() dtype=float32_ref&gt; å‘çŽ°ï¼Œâ€™Yâ€™å˜é‡åè™½ç„¶å·²ç»è¢«å ç”¨äº†ï¼Œä½†æ˜¯åœ¨TensorFlowä¸­å¹¶ä¸ä¼šå¯¹éžtf.get_variable()æ–¹æ³•äº§ç”Ÿå‘½åå†²çªã€‚ä¸‹é¢å°±ç”¨tf.trainable_variables()å‡½æ•°æŸ¥çœ‹å·¥ä½œåŒºçš„å˜é‡ã€‚tf.trainable_variables()å¯ä»¥å°†æ‰€æœ‰trainable=Trueçš„å˜é‡ä»¥listçš„å½¢å¼è¿”å›žã€‚ 12345vs = tf.trainable_variables()#æ­¤å¤„çš„vsæ˜¯ä¸€ä¸ªlistprint len(vs)for v in vs: print v 1234565&lt;tf.Variable &apos;Variable:0&apos; shape=(2,) dtype=float32_ref&gt;&lt;tf.Variable &apos;Y:0&apos; shape=(2,) dtype=float32_ref&gt;&lt;tf.Variable &apos;Y_1:0&apos; shape=(2,) dtype=float32_ref&gt;&lt;tf.Variable &apos;fl:0&apos; shape=() dtype=float32_ref&gt;&lt;tf.Variable &apos;Y_2:0&apos; shape=() dtype=float32_ref&gt; ç»“è®ºðŸ‘†çš„å®žéªŒå¯ä»¥å¾—å‡ºä¸€ä¸ªç®€å•çš„ç»“è®ºï¼Œå°±æ˜¯åªæœ‰é€šè¿‡tf.get_variable()æ–¹å¼åˆ›å»ºçš„å˜é‡ä¼šå‘ç”Ÿå‘½åå†²çªï¼Œå¹¶ä¸”tf.get_variable()ä¸Žå…¶ä»–å˜é‡åˆ›å»ºçš„æ–¹å¼ä¹Ÿä¸ä¼šå‘ç”Ÿå‘½åå†²çªã€‚ç®€å•æ€»ç»“ä¸€ä¸‹ä¸‰ç§å˜é‡å‘½åçš„æ–¹å¼ã€‚ tf.placeholder()trainable=False tf.Variable()trainable=True/False tf.get_variable()ä¸€èˆ¬ä¸Žtf.variable_scope()ä¸€èµ·ä½¿ç”¨æ¥å®žçŽ°ç¥žç»ç½‘ç»œä¸­çš„å˜é‡å…±äº«é—®é¢˜ã€‚ å‘½åç©ºé—´å’Œå˜é‡ç©ºé—´TensorFlowä¸­æœ‰ä¸¤ç§å‘½åç©ºé—´ï¼Œname_scopeå’Œvariable_scope 123456789import tensorflow as tfwith tf.name_scope(&apos;nspace&apos;): v1 = tf.Variable([1], name=&apos;v1&apos;) with tf.variable_scope(&apos;vspace&apos;): v2 = tf.Variable([1], name=&apos;v2&apos;) v3 = tf.get_variable(name=&apos;v3&apos;,shape=[])print &apos;v1.name:&apos;, v1.nameprint &apos;v2.name:&apos;, v2.nameprint &apos;v3.name:&apos;, v3.name 123v1.name: nspace/v1:0v2.name: nspace/vspace/v2:0v3.name: vspace/v3:0 å¯ä»¥çœ‹åˆ°ç”¨tf.get_variable()æ–¹æ³•åˆ›å»ºçš„å˜é‡ä¸ä¼šå—tf.name_scope()å‘½åç©ºé—´çš„å½±å“ã€‚è€Œtf.get_variable()å’Œtf.variable_scope()ä¸€èµ·å®žçŽ°äº†å˜é‡çš„å…±äº«ã€‚ tf.Variable()åˆ›å»ºå˜é‡123456789101112131415161718#é¦–å…ˆæ¸…ç©ºå½“å‰å·¥ä½œåŒºçš„å˜é‡import tensorflow as tfdef my_image_filter(): conv1_weights = tf.Variable(tf.random_normal([5,5,32,32]),name=&apos;conv1_weights&apos;) conv1_biase = tf.Variable(tf.zeros([32]),name=&apos;conv1_biases&apos;) conv2_weights = tf.Variable(tf.random_normal([5,5,32,32]),name=&apos;conv2_weights&apos;) conv2_biases = tf.Variable(tf.zeros([32]),name=&apos;conv2_biases&apos;) return None #First callresult1 = my_image_filter()#Another callresult2 = my_image_filter()#è¿”å›žæ‰€æœ‰å¯è®­ç»ƒçš„å˜é‡åˆ°vsåˆ—è¡¨ä¸­vs = tf.trainable_variables()print &apos;There are %d trainable_variables in the Graph:&apos; % len(vs)for v in vs: print v 123456789There are 8 trainable_variables in the Graph:&lt;tf.Variable &apos;conv1_weights:0&apos; shape=(5, 5, 32, 32) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv1_biases:0&apos; shape=(32,) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv2_weights:0&apos; shape=(5, 5, 32, 32) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv2_biases:0&apos; shape=(32,) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv1_weights_1:0&apos; shape=(5, 5, 32, 32) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv1_biases_1:0&apos; shape=(32,) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv2_weights_1:0&apos; shape=(5, 5, 32, 32) dtype=float32_ref&gt;&lt;tf.Variable &apos;conv2_biases_1:0&apos; shape=(32,) dtype=float32_ref&gt; å·¥ä½œåŒºå†…æœ‰8ä¸ªå˜é‡ï¼Œå› ä¸ºè°ƒç”¨äº†ä¸¤æ¬¡my_image_filter()å‡½æ•°ï¼Œæ¯è°ƒç”¨ä¸€æ¬¡éƒ½ä¼šé‡æ–°åˆ›å»º4ä¸ªå˜é‡ã€‚ ç”¨tf.get_variable()åˆ›å»ºå˜é‡123456789101112131415161718192021222324252627import tensorflow as tfdef conv_relu(kernel_shape, bias_shape): # Create variable named &quot;weights&quot;. weights = tf.get_variable(&quot;weights&quot;, kernel_shape, initializer=tf.random_normal_initializer()) # Create variable named &quot;biases&quot;. biases = tf.get_variable(&quot;biases&quot;, bias_shape, initializer=tf.constant_initializer(0.0)) return Nonedef my_image_filter(): with tf.variable_scope(&quot;conv1&quot;): # Variables created here will be named &quot;conv1/weights&quot;, &quot;conv1/biases&quot;. relu1 = conv_relu([5, 5, 32, 32], [32]) with tf.variable_scope(&quot;conv2&quot;): # Variables created here will be named &quot;conv2/weights&quot;, &quot;conv2/biases&quot;. return conv_relu( [5, 5, 32, 32], [32])with tf.variable_scope(&quot;image_filters&quot;) as scope: result1 = my_image_filter() scope.reuse_variables() result2 = my_image_filter()vs = tf.trainable_variables()print &apos;There are %d train_able_variables in the Graph: &apos; % len(vs)for v in vs: print v 12345There are 4 train_able_variables in the Graph: &lt;tf.Variable &apos;image_filters/conv1/weights:0&apos; shape=(5, 5, 32, 32) dtype=float32_ref&gt;&lt;tf.Variable &apos;image_filters/conv1/biases:0&apos; shape=(32,) dtype=float32_ref&gt;&lt;tf.Variable &apos;image_filters/conv2/weights:0&apos; shape=(5, 5, 32, 32) dtype=float32_ref&gt;&lt;tf.Variable &apos;image_filters/conv2/biases:0&apos; shape=(32,) dtype=float32_ref&gt; ðŸ‘†çš„ç¨‹åºè™½ç„¶è°ƒç”¨äº†ä¸¤æ¬¡å‡½æ•°ï¼Œä½†æ˜¯å¼•ç”¨äº†å˜é‡å˜é‡çš„æœºåˆ¶ï¼Œæˆ‘ä»¬åªåˆ›å»ºäº†ä¸€æ¬¡å˜é‡ã€‚å®žçŽ°äº†å˜é‡å…±äº«ã€‚]]></content>
      <tags>
        <tag>å­¦ä¹ ç¬”è®°</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[åœ¨Markdownä¸­ä½¿ç”¨å›¾åºŠçš„ç¤ºä¾‹]]></title>
    <url>%2F2018%2F03%2F15%2F%E5%9C%A8Markdown%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%9B%BE%E5%BA%8A%E7%9A%84%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[markdownä¸­å›¾åºŠä½¿ç”¨ç¤ºä¾‹ hhhhæœ‰ç‚¹å¤¸å¼ äº†ï¼Œåœ¨markdownä¸­æ·»åŠ å›¾ç‰‡å…¶å®žå¾ˆç®€å•ï¼Œ![Markdown](Image URL)å°±å¯ä»¥äº†ã€‚ æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å¾€åšå®¢ä¸­æ·»åŠ å›¾ç‰‡ï¼Œä¸€ç§æ˜¯å°†å›¾ç‰‡æ”¾åˆ°æœ¬åœ°çš„sourceæ–‡ä»¶ä¸­ï¼Œä½†æ˜¯è¿™ç§å½“å›¾ç‰‡è¿‡å¤šæˆ–è¿‡å¤§æ—¶ä¼šå æ®å¤§é‡å­˜å‚¨ç©ºé—´å¯¼è‡´ç½‘ç«™åŠ è½½ç¼“æ…¢ã€‚è¿™ä¸ªæ—¶å€™å°±è¦ç”¨åˆ°å›¾åºŠè¿™ä¸ªå·¥å…·ã€‚ å›¾åºŠå°±æ˜¯å­˜å‚¨å›¾ç‰‡çš„æœåŠ¡å™¨ï¼Œä¸Šä¼ æœ¬åœ°å›¾ç‰‡ä¼šç”Ÿæˆä¸€ä¸ªURLé“¾æŽ¥ï¼ŒæŠŠé“¾æŽ¥ç²˜è´´åˆ°mdæ–‡ä»¶ä¸­å³å¯ã€‚è¿™é‡Œæˆ‘ä½¿ç”¨çš„æ˜¯è´´å›¾åº“ï¼Œwww.tietuku.comã€‚è¿˜æœ‰å¾ˆå¤šè¿™ç§å…è´¹çš„å›¾åºŠï¼Œé€‰æ‹©ä¸€ä¸ªè‡ªå·±å–œæ¬¢çš„å³å¯ã€‚ P.S.æ—©ä¸Šè¿˜è¯´å®žéªŒå®¤æ²¡äº‹æ™šä¸Šå°±æ¥äº†ï¼ŒæŽ¥ä¸‹æ¥åº”è¯¥ä¼šå¥½å¥½çœ‹çœ‹CNNå’ŒLSTMã€‚ä¼šå†™ä¸€ç‚¹å­¦ä¹ ç¬”è®°å•¥çš„ï¼ˆä¹±ç«‹flagï¼‰äº†ï¼Œæºœäº†æºœäº†ðŸ¤¦â€â™€ï¸]]></content>
      <tags>
        <tag>å­¦ä¹ ç¬”è®°</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[First Blog]]></title>
    <url>%2F2018%2F03%2F15%2FFirst%20Blog%2F</url>
    <content type="text"><![CDATA[With great power comes great responsibility. First BlogæŠ˜è…¾äº†ä¸¤å¤©ï¼ŒHexoæ¡†æž¶âž•GitHubéƒ¨ç½²âž•åŸŸåè§£æžç»ˆäºŽç®€å•æ­èµ·æ¥äº†ä¸€ä¸ªåšå®¢ã€‚å¾ˆæ—©å°±æƒ³ç”¨åšå®¢è®°å½•ä¸€ä¸‹å¹³æ—¶å­¦ä¹ ä¸Šè¯¾ä¸Šé‡åˆ°çš„é—®é¢˜ðŸ‘»ï¼ŒçŽ°åœ¨æ­£å¥½è¶ç€å®žéªŒå®¤æ²¡ä»€ä¹ˆäº‹æƒ…çŽ©ä¸€çŽ©ï¼Œå¸Œæœ›è‡ªå·±èƒ½å¤ŸåšæŒä¸‹åŽ»å§å˜»å˜»ï¼ˆç‹—å¤´ è‡ªå·±è„‘è¡¥ï¼‰ã€‚]]></content>
      <tags>
        <tag>å­¦ä¹ ç¬”è®°</tag>
      </tags>
  </entry>
</search>
